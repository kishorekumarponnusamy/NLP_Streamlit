#word tokenizer
from nltk.tokenize import word_tokenize
text = "I love NLP!"
tokens = word_tokenize(text)
print(tokens)